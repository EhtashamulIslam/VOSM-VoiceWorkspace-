You are my expert full-stack assistant. I am building Voice-Operated Smart Workspace (VOSW): a productivity web app where users control their desktop, manage files, write documents and generate code using voice + text commands.
The frontend is React (web app). The backend is Flask (Python). Use a local on-device assistant where possible for privacy.

Your responsibilities:

Design system architecture, folder structure, and API contract (Flask REST + WebSocket).

Produce production-ready Flask and React code (clean, modular, commented).

Recommend libraries for voice capture, speech-to-text, command parsing, local LLM integration, and safe file/OS operations.

Implement endpoints for: create file/folder, edit file contents, search files, run safe OS actions (open app), and run AI summarization/generation locally.

Suggest a defense model: authentication, permission checks, sandboxing, and an allowlist for executable commands.

Offer UI/UX suggestions and a developer setup guide.

Core features: microphone capture, speechâ†’text (browser or local), natural language command parsing, filesystem integration, local on-device LLM for private generation, real-time feedback via WebSocket.

How you should respond: provide an architecture overview, stack and libs, a recommended folder structure, example Flask routes and SocketIO code, and a minimal React voice capture snippet. Include security considerations and step-by-step setup instructions.

Start by giving me:

Text-based architecture diagram.

Recommended stack & libraries with short reasons.

Folder structure for React + Flask.

Minimal Flask server code (REST + SocketIO) with endpoints for command, create-file, search.

React example for capturing audio and sending it to the server.

Security checklist and recommended allowlist policy.

ðŸ”§ Recommended stack & libraries

Backend: Flask, Flask-SocketIO (real-time), Flask-RESTful or Flask blueprints.

Async worker (optional): Celery or RQ for heavy local LLM tasks.

Local LLM / assistant: llama-cpp-python, transformers (local), or gpt4all (if you want offline). Use a lightweight model for on-device.

Speech-to-text: Prefer browser Web Speech API (fast, privacy-friendly since audio never leaves host if you choose on-device STT) OR send audio to local Python STT using whisper (openai/whisper, faster if small model).

Frontend voice capture: Web Audio API + MediaRecorder.

File ops / OS control: Python pathlib, os, shutil, and for limited OS commands subprocess with strict allowlist.

NLP/command parsing: Use LLM (local) + rules/regex fallback.

Auth & security: JWT for local login or OS user-level auth, HTTPS for remote, CSRF protection if needed.

Dev tooling: Docker for reproducible local environment.